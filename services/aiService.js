// services/aiService.js
import { GoogleGenerativeAI } from '@google/generative-ai';

export class AIService {
  constructor(
    googleApiKey = process.env.GOOGLE_API_KEY,
    grokApiKey = process.env.GROK_API_KEY
  ) {
    this.genAI = new GoogleGenerativeAI(googleApiKey);
    this.grokApiKey = grokApiKey;
    this.embeddingModel = this.genAI.getGenerativeModel({ model: 'text-embedding-004' });
    this.chatModel = this.genAI.getGenerativeModel({ model: 'gemini-2.0-flash-exp' });
    
    this.personaEdu = `Voc√™ √© Edu, um assistente educacional especializado nos materiais dispon√≠veis.

PRINC√çPIO FUNDAMENTAL:
- Toda informa√ß√£o deve vir EXCLUSIVAMENTE dos materiais de refer√™ncia fornecidos
- Nunca invente informa√ß√µes fora do contexto fornecido
- Sempre cite a fonte espec√≠fica (arquivo e p√°gina quando dispon√≠vel)

ESTILO DE RESPOSTA:
- Direto e informativo
- Sempre referencie a fonte no formato: "[Nome do Arquivo, P√°gina X]"
- Agrupe informa√ß√µes por fonte quando poss√≠vel
- Seja natural mas preciso`;
  }

  async createEmbedding(text) {
    try {
      const result = await this.embeddingModel.embedContent(text);
      return result.embedding.values;
    } catch (error) {
      console.error('Erro ao criar embedding:', error);
      throw new Error('Falha ao criar embedding: ' + error.message);
    }
  }

  // GERAR BOAS-VINDAS COM T√ìPICOS DISPON√çVEIS
  async gerarBoasVindasComTopicos(topicos, estatisticas) {
    const topicosTexto = topicos.slice(0, 5).join(', ');
    const totalTopicos = estatisticas.total_topicos || topicos.length;
    const totalDocumentos = estatisticas.total_documentos || 0;

    const prompt = `${this.personaEdu}

Voc√™ est√° dando boas-vindas ao usu√°rio e apresentando os t√≥picos dispon√≠veis.

T√ìPICOS PRINCIPAIS: ${topicosTexto}
TOTAL DE T√ìPICOS: ${totalTopicos}
TOTAL DE DOCUMENTOS: ${totalDocumentos}

Gere uma mensagem de boas-vindas que:
1. Se apresente como Edu
2. Mencione os principais t√≥picos dispon√≠veis
3. Convide o usu√°rio a perguntar sobre esses t√≥picos
4. Seja acolhedor e informativo

N√£o use markdown, seja natural.`;

    try {
      const result = await this.chatModel.generateContent({
        contents: [{ role: 'user', parts: [{ text: prompt }] }],
        generationConfig: { 
          temperature: 0.8, 
          maxOutputTokens: 400 
        }
      });
      
      return result.response.text();
    } catch (error) {
      // Fallback
      return `Ol√°! üëã Sou o Edu, seu assistente educacional!

Tenho materiais sobre ${topicosTexto} e mais ${totalTopicos - 5} outros t√≥picos.

Com base no que tenho dispon√≠vel, posso te ajudar com explica√ß√µes, exemplos e tirar d√∫vidas. O que gostaria de aprender hoje?`;
    }
  }

  // RESPOSTA COM REFER√äNCIAS ESPEC√çFICAS AOS MATERIAIS
  async responderComReferenciasEspecificas(mensagem, historico = [], fragmentos = [], preferencias = null) {
    // Agrupar fragmentos por arquivo para organiza√ß√£o
    const fragmentosPorArquivo = this.agruparFragmentosPorArquivo(fragmentos);
    
    const systemPrompt = `${this.personaEdu}

PERGUNTA DO USU√ÅRIO: "${mensagem}"

MATERIAIS DE REFER√äNCIA DISPON√çVEIS:
${this.formatarMateriaisParaPrompt(fragmentosPorArquivo)}

REGRAS ESTRITAS:
1. Use APENAS as informa√ß√µes dos materiais acima
2. Sempre cite a fonte no formato: "[Nome do Arquivo, P√°gina X]"
3. Se n√£o souber a p√°gina, cite apenas o arquivo: "[Nome do Arquivo]"
4. Agrupe informa√ß√µes por fonte quando poss√≠vel
5. Seja direto e evite repeti√ß√µes
6. Se os materiais n√£o cobrirem completamente a pergunta, seja honesto sobre as limita√ß√µes

FORMATO PREFERIDO:
- Responda diretamente √† pergunta
- Use frases como: "Nos materiais dispon√≠veis..." ou "Conforme consta em..."
- Cite a fonte ao final de cada informa√ß√£o relevante
- Seja natural mas preciso`;

    try {
      const conversationHistory = historico.map(msg => ({
        role: msg.role === 'user' ? 'user' : 'model',
        parts: [{ text: msg.content }]
      }));

      const result = await this.chatModel.generateContent({
        contents: [
          ...conversationHistory,
          { role: 'user', parts: [{ text: systemPrompt }] }
        ],
        generationConfig: { 
          temperature: 0.7, 
          maxOutputTokens: 2048 
        }
      });

      const resposta = result.response.text();
      return this.validarReferenciasNaResposta(resposta, fragmentosPorArquivo);

    } catch (error) {
      console.error('Erro ao gerar resposta com refer√™ncias:', error);
      return this.gerarRespostaFallback(fragmentosPorArquivo, mensagem);
    }
  }

  // AGRUPAR FRAGMENTOS POR ARQUIVO
  agruparFragmentosPorArquivo(fragmentos) {
    const agrupados = {};
    
    fragmentos.forEach(fragmento => {
      const nomeArquivo = fragmento.metadados.arquivo_nome;
      if (!agrupados[nomeArquivo]) {
        agrupados[nomeArquivo] = {
          arquivo: nomeArquivo,
          tipo: fragmento.metadados.tipo,
          fragmentos: []
        };
      }
      
      agrupados[nomeArquivo].fragmentos.push({
        conteudo: fragmento.conteudo,
        pagina: fragmento.metadados.localizacao?.pagina,
        secao: fragmento.metadados.localizacao?.secao,
        score: fragmento.score_final || fragmento.score
      });
    });

    return agrupados;
  }

  // FORMATAR MATERIAIS PARA O PROMPT
  formatarMateriaisParaPrompt(fragmentosPorArquivo) {
    return Object.values(fragmentosPorArquivo).map(arquivo => {
      const paginas = [...new Set(arquivo.fragmentos.map(f => f.pagina).filter(p => p))];
      const infoPaginas = paginas.length > 0 ? ` (P√°ginas: ${paginas.join(', ')})` : '';
      
      return `
ARQUIVO: ${arquivo.arquivo}${infoPaginas}
CONTE√öDO:
${arquivo.fragmentos.map(f => {
  const infoPagina = f.pagina ? ` [p√°g. ${f.pagina}]` : '';
  return `‚Ä¢ ${f.conteudo}${infoPagina}`;
}).join('\n')}
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ`;
    }).join('\n');
  }

  // VALIDAR SE A RESPOSTA CONT√âM REFER√äNCIAS
  validarReferenciasNaResposta(resposta, fragmentosPorArquivo) {
    const nomesArquivos = Object.keys(fragmentosPorArquivo);
    const temReferencias = nomesArquivos.some(nome => resposta.includes(nome));
    
    if (!temReferencias && nomesArquivos.length > 0) {
      // Adicionar refer√™ncia automaticamente se a IA esqueceu
      const primeiroArquivo = nomesArquivos[0];
      const primeiraPagina = fragmentosPorArquivo[primeiroArquivo].fragmentos[0]?.pagina;
      
      return `${resposta}\n\nFonte: [${primeiroArquivo}${primeiraPagina ? `, p√°g. ${primeiraPagina}` : ''}]`;
    }
    
    return resposta;
  }

  // RESPOSTA DE FALLBACK
  gerarRespostaFallback(fragmentosPorArquivo, mensagem) {
    const arquivos = Object.keys(fragmentosPorArquivo);
    
    if (arquivos.length === 0) {
      return `Desculpe, n√£o encontrei materiais espec√≠ficos sobre "${mensagem}" na base de conhecimento dispon√≠vel.`;
    }

    const principaisArquivos = arquivos.slice(0, 3);
    let resposta = `Encontrei informa√ß√µes relacionadas a "${mensagem}" nos seguintes materiais:\n\n`;

    principaisArquivos.forEach(arquivo => {
      const frags = fragmentosPorArquivo[arquivo].fragmentos;
      const paginas = [...new Set(frags.map(f => f.pagina).filter(p => p))];
      
      resposta += `‚Ä¢ ${arquivo}`;
      if (paginas.length > 0) {
        resposta += ` (p√°ginas ${paginas.join(', ')})`;
      }
      resposta += '\n';
    });

    resposta += `\nPosso te explicar mais sobre algum aspecto espec√≠fico baseado nesses materiais?`;

    return resposta;
  }

  // SUGERIR T√ìPICOS DISPON√çVEIS
  async sugerirTopicosDisponiveis(topicos, mensagem, historico = []) {
    const topicosTexto = topicos.slice(0, 8).join(', ');
    
    const prompt = `${this.personaEdu}

O usu√°rio perguntou sobre: "${mensagem}"
No momento, meus materiais cobrem principalmente estes t√≥picos: ${topicosTexto}

Sugira de forma natural que podemos ajudar com esses t√≥picos e pergunte qual interessa mais.

Seja acolhedor e incentive a explora√ß√£o dos t√≥picos dispon√≠veis.`;

    try {
      const conversationHistory = historico.map(msg => ({
        role: msg.role === 'user' ? 'user' : 'model',
        parts: [{ text: msg.content }]
      }));

      const result = await this.chatModel.generateContent({
        contents: [
          ...conversationHistory,
          { role: 'user', parts: [{ text: prompt }] }
        ],
        generationConfig: { 
          temperature: 0.8, 
          maxOutputTokens: 300 
        }
      });
      
      return result.response.text();
    } catch (error) {
      return `Sobre "${mensagem}", posso te ajudar com: ${topicosTexto}. \n\nQual desses t√≥picos te interessa mais?`;
    }
  }

  // SUGERIR APROXIMA√á√ÉO DE T√ìPICO
  async sugerirAproximacaoTopico(topicosRelevantes, mensagem, historico = []) {
    const topicosTexto = topicosRelevantes.slice(0, 5).join(', ');
    
    const prompt = `${this.personaEdu}

O usu√°rio perguntou sobre: "${mensagem}"
Encontrei materiais relacionados a: ${topicosTexto}

Sugira esses t√≥picos relacionados e pergunte se algum deles atende ao interesse do usu√°rio.

Seja √∫til e direto.`;

    try {
      const result = await this.chatModel.generateContent({
        contents: [{ role: 'user', parts: [{ text: prompt }] }],
        generationConfig: { 
          temperature: 0.7, 
          maxOutputTokens: 250 
        }
      });
      
      return result.response.text();
    } catch (error) {
      return `Encontrei materiais sobre: ${topicosTexto}. \n\nAlgum desses t√≥picos atende sua necessidade?`;
    }
  }

  // M√âTODO DE FALLBACK PARA GROK (mantido para compatibilidade)
  async _callGrokAPI(messages, temperature = 0.8, maxTokens = 2048) {
    if (!this.grokApiKey) {
      throw new Error('Grok API key n√£o configurada');
    }

    const response = await fetch('https://api.x.ai/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${this.grokApiKey}`
      },
      body: JSON.stringify({
        model: 'grok-4-fast-reasoning',
        messages: messages,
        temperature: temperature,
        max_tokens: maxTokens
      })
    });

    if (!response.ok) {
      throw new Error(`Grok API error: ${response.status}`);
    }

    const data = await response.json();
    return data.choices[0].message.content;
  }
}